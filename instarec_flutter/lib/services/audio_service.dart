import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as path;
import 'package:share_plus/share_plus.dart';

// Circular Buffer for audio data
class CircularBuffer {
  final Uint8List _buffer;
  int _writePos = 0;
  int _readPos = 0;
  bool _isFull = false;
  final int _sampleRate = 44100;
  final int _bytesPerSample = 2; // 16-bit = 2 bytes
  
  CircularBuffer(int maxDurationSeconds) 
    : _buffer = Uint8List(maxDurationSeconds * 44100 * 2);
  
  // Write audio data to buffer
  void write(Uint8List data) {
    for (int i = 0; i < data.length; i++) {
      _buffer[_writePos] = data[i];
      _writePos = (_writePos + 1) % _buffer.length;
      
      if (_writePos == _readPos) {
        _isFull = true;
        _readPos = (_readPos + 1) % _buffer.length;
      }
    }
  }
  
  // Read N seconds of audio data (ìµœê·¼ Nì´ˆ)
  Uint8List readSeconds(int seconds) {
    final bytesToRead = seconds * _sampleRate * _bytesPerSample;
    
    // ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ê³„ì‚°
    int availableBytes;
    if (_isFull) {
      availableBytes = _buffer.length;
    } else {
      availableBytes = _writePos;
    }

    // ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥í•œ ë§Œí¼ë§Œ ì½ê¸°
    final actualBytesToRead = availableBytes < bytesToRead ? availableBytes : bytesToRead;

    // ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
    if (actualBytesToRead == 0) {
      return Uint8List(0);
    }
    
    final result = Uint8List(actualBytesToRead);
    
    // writePosì—ì„œ ì—­ìˆœìœ¼ë¡œ Nì´ˆë§Œí¼ ì½ê¸°
    int readPos = _writePos;
    
    for (int i = 0; i < actualBytesToRead; i++) {
      // ì—­ìˆœìœ¼ë¡œ ì´ë™
      readPos = (readPos - 1 + _buffer.length) % _buffer.length;
      // ê²°ê³¼ëŠ” ì •ìˆœìœ¼ë¡œ ì €ì¥ (ìµœì‹  ë°ì´í„°ê°€ ë’¤ì— ì˜¤ë„ë¡)
      result[actualBytesToRead - 1 - i] = _buffer[readPos];
    }
    
    return result;
  }
  
  // Get current buffer status
  Map<String, dynamic> getStatus() {
    return {
      'writePos': _writePos,
      'readPos': _readPos,
      'isFull': _isFull,
      'bufferSize': _buffer.length,
      'availableSeconds': _isFull 
          ? _buffer.length ~/ (_sampleRate * _bytesPerSample) 
          : _writePos ~/ (_sampleRate * _bytesPerSample),
    };
  }
}

class AudioService {
  final AudioRecorder _audioRecorder = AudioRecorder();
  StreamSubscription<Uint8List>? _audioStreamSubscription;
  
  // Callback for state updates
  Function()? _onStateChanged;
  
  // Buffer duration setting (default)
  int _bufferDuration = 10;
  
  // Circular buffer system
  CircularBuffer? _circularBuffer;

  // Recording state
  bool _isRecording = false;

  // Getters
  bool get isRecording => _isRecording;
  int get bufferDuration => _bufferDuration;

  // Initialize audio service
  Future<void> initialize({Function()? onStateChanged}) async {
    if (await _audioRecorder.hasPermission()) {
      _onStateChanged = onStateChanged;
    } else {
      throw Exception('ë§ˆì´í¬ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤');
    }
  }

  // Get accessible storage directory for saving files
  Future<Directory> _getAccessibleDirectory() async {
    if (Platform.isIOS) {
      final directory = await getApplicationDocumentsDirectory();
      final recordingsDir = Directory(path.join(directory.path, 'recordings'));
      if (!await recordingsDir.exists()) {
        await recordingsDir.create(recursive: true);
      }
      return recordingsDir;
    } else {
      final directory = await getExternalStorageDirectory();
      final recordingsDir = Directory(path.join(directory!.path, 'InstaRec', 'recordings'));
      if (!await recordingsDir.exists()) {
        await recordingsDir.create(recursive: true);
      }
      return recordingsDir;
    }
  }

  // Get playable directory for audio playback
  Future<Directory> _getPlayableDirectory() async {
    if (Platform.isIOS) {
      final directory = await getTemporaryDirectory();
      final playableDir = Directory(path.join(directory.path, 'playable_recordings'));
      if (!await playableDir.exists()) {
        await playableDir.create(recursive: true);
      }
      return playableDir;
    } else {
      return await _getAccessibleDirectory();
    }
  }

  // Copy file to playable location
  Future<String> copyToPlayableLocation(String originalPath) async {
    if (Platform.isAndroid) {
      return originalPath;
    }
    
    final playableDir = await _getPlayableDirectory();
    final fileName = path.basename(originalPath);
    final playablePath = path.join(playableDir.path, fileName);
    
    final originalFile = File(originalPath);
    if (await originalFile.exists()) {
      await originalFile.copy(playablePath);
    }
    
    return playablePath;
  }

  // Start continuous recording with circular buffer
  Future<void> startContinuousRecording() async {
    if (_isRecording) return;

    try {
      _circularBuffer = CircularBuffer(300);
      
      // ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ PCM ë°ì´í„° ë°›ê¸°
      final stream = await _audioRecorder.startStream(
        RecordConfig(
          encoder: AudioEncoder.pcm16bits,
          sampleRate: 44100,
          numChannels: 1,
        ),
      );

      // ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ CircularBufferì— ì“°ê¸°
      _audioStreamSubscription = stream.listen((data) {
        _circularBuffer?.write(data);
      });

      _isRecording = true;
      _onStateChanged?.call();

      if (kDebugMode) {
        print('ğŸ¤ ìŠ¤íŠ¸ë¦¼ ë…¹ìŒ ì‹œì‘');
        print('ğŸ“¦ Circular Buffer ìƒì„± ì™„ë£Œ (300ì´ˆ ìš©ëŸ‰)');
      }
    } catch (e) {
      if (kDebugMode) {
        print('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e');
      }
      rethrow;
    }
  }

  // Stop continuous recording (ì €ì¥ ì—†ì´ ì¤‘ì§€ë§Œ)
  Future<void> stopContinuousRecording() async {
    if (!_isRecording) return;

    try {
      await _audioStreamSubscription?.cancel();
      await _audioRecorder.stop();
      
      _isRecording = false;
      _onStateChanged?.call();
      
      if (kDebugMode) {
        print('ğŸ›‘ ë…¹ìŒ ì¤‘ì§€');
      }
    } catch (e) {
      if (kDebugMode) {
        print('âŒ ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨: $e');
      }
      rethrow;
    }
  }

  // ğŸ†• ìµœê·¼ Nì´ˆë¥¼ ìº¡ì²˜í•´ì„œ íŒŒì¼ë¡œ ì €ì¥
  Future<Map<String, dynamic>> getCapture(int seconds) async {
    if (!_isRecording) {
      throw Exception('ë…¹ìŒì´ ì§„í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤');
    }

    if (_circularBuffer == null) {
      throw Exception('CircularBufferê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }

    try {
      // Generate output filename
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      final recordingsDir = await _getAccessibleDirectory();
      final wavPath = path.join(recordingsDir.path, 'capture_$timestamp.wav');

      // Read N seconds of audio data from circular buffer
      final audioData = _circularBuffer!.readSeconds(seconds);
      
      if (audioData.isEmpty) {
        throw Exception('ë²„í¼ì— ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');
      }
      
      // Create WAV file from audio data
      await _createWavFile(audioData, wavPath);
      
      // ì‹¤ì œ ì €ì¥ëœ ì‹œê°„ ê³„ì‚°
      final actualSeconds = audioData.length / (_circularBuffer!._sampleRate * _circularBuffer!._bytesPerSample);
      
      final fileInfo = {
        'wavPath': wavPath,
        'timestamp': timestamp,
        'captureTime': DateTime.now().toIso8601String(),
        'requestedSeconds': seconds,
        'actualSeconds': actualSeconds,
        'fileName': 'capture_$timestamp.wav',
        'fileSize': await File(wavPath).length(),
      };

      if (kDebugMode) {
        print('ğŸ’¾ ìº¡ì²˜ ì™„ë£Œ: $wavPath');
        print('ğŸ“Š ìš”ì²­: ${seconds}ì´ˆ / ì‹¤ì œ: ${actualSeconds.toStringAsFixed(1)}ì´ˆ');
      }
      
      return fileInfo;
    } catch (e) {
      if (kDebugMode) {
        print('âŒ ìº¡ì²˜ ì €ì¥ ì‹¤íŒ¨: $e');
      }
      rethrow;
    }
  }

  // ğŸ”„ ê¸°ì¡´ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
  @Deprecated('Use getCapture(seconds) instead')
  Future<void> startCapture() async {
    // ì´ì œëŠ” ì•„ë¬´ ë™ì‘ ì•ˆ í•¨ (CircularBufferê°€ í•­ìƒ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ)
    if (kDebugMode) {
      print('âš ï¸ startCapture()ëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. getCapture(N)ì„ ì‚¬ìš©í•˜ì„¸ìš”.');
    }
  }

  @Deprecated('Use getCapture(seconds) instead')
  Future<Map<String, dynamic>> stopCapture() async {
    // getCapture()ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ë¦¬ë‹¤ì´ë ‰íŠ¸
    return await getCapture(_bufferDuration);
  }

  // Get all saved files
  Future<List<Map<String, dynamic>>> getSavedFiles() async {
    try {
      final recordingsDir = await _getAccessibleDirectory();
      final files = <Map<String, dynamic>>[];
      
      if (await recordingsDir.exists()) {
        final fileList = await recordingsDir.list().toList();
        for (final file in fileList) {
          if (file is File && file.path.endsWith('.wav')) {
            final stat = await file.stat();
            files.add({
              'wavPath': file.path,
              'fileName': path.basename(file.path),
              'timestamp': stat.modified.millisecondsSinceEpoch,
              'fileSize': stat.size,
              'modifiedTime': stat.modified.toIso8601String(),
            });
          }
        }
      }
      
      files.sort((a, b) => b['timestamp'].compareTo(a['timestamp']));
      return files;
    } catch (e) {
      if (kDebugMode) {
        print('âŒ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: $e');
      }
      return [];
    }
  }

  // Delete file
  Future<bool> deleteFile(String filePath) async {
    try {
      final file = File(filePath);
      if (await file.exists()) {
        await file.delete();
        if (kDebugMode) {
          print('ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: $filePath');
        }
        return true;
      }
      return false;
    } catch (e) {
      if (kDebugMode) {
        print('âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: $e');
      }
      return false;
    }
  }

  // Share file
  Future<void> shareFile(String filePath) async {
    try {
      await Share.shareXFiles([XFile(filePath)], text: 'InstaRec ë…¹ìŒ íŒŒì¼');
    } catch (e) {
      if (kDebugMode) {
        print('âŒ íŒŒì¼ ê³µìœ  ì‹¤íŒ¨: $e');
      }
      rethrow;
    }
  }


  // Create WAV file from audio data
  Future<void> _createWavFile(Uint8List audioData, String filePath) async {
    final wavHeader = _createWavHeader(audioData.length);
    
    final file = File(filePath);
    final sink = file.openWrite();
    
    sink.add(wavHeader);
    sink.add(audioData);
    
    await sink.close();
  }

  // Create WAV file header
  Uint8List _createWavHeader(int dataSize) {
    final header = ByteData(44);
    final sampleRate = 44100;
    
    // RIFF header
    header.setUint8(0, 0x52); // 'R'
    header.setUint8(1, 0x49); // 'I'
    header.setUint8(2, 0x46); // 'F'
    header.setUint8(3, 0x46); // 'F'
    header.setUint32(4, 36 + dataSize, Endian.little);
    
    // WAVE format
    header.setUint8(8, 0x57);  // 'W'
    header.setUint8(9, 0x41);  // 'A'
    header.setUint8(10, 0x56); // 'V'
    header.setUint8(11, 0x45); // 'E'
    
    // fmt chunk
    header.setUint8(12, 0x66); // 'f'
    header.setUint8(13, 0x6D); // 'm'
    header.setUint8(14, 0x74); // 't'
    header.setUint8(15, 0x20); // ' '
    header.setUint32(16, 16, Endian.little);
    header.setUint16(20, 1, Endian.little);
    header.setUint16(22, 1, Endian.little);
    header.setUint32(24, sampleRate, Endian.little);
    header.setUint32(28, sampleRate * 2, Endian.little);
    header.setUint16(32, 2, Endian.little);
    header.setUint16(34, 16, Endian.little);
    
    // data chunk
    header.setUint8(36, 0x64); // 'd'
    header.setUint8(37, 0x61); // 'a'
    header.setUint8(38, 0x74); // 't'
    header.setUint8(39, 0x61); // 'a'
    header.setUint32(40, dataSize, Endian.little);
    
    return header.buffer.asUint8List();
  }

  // Set buffer duration (default value for backward compatibility)
  void setBufferDuration(int duration) {
    if (duration >= 10 && duration <= 300) {
      _bufferDuration = duration;
    }
  }

  // Get buffer status
  Map<String, dynamic> getBufferStatus() {
    return {
      'bufferDuration': _bufferDuration,
      'isRecording': _isRecording,
      'circularBufferStatus': _circularBuffer?.getStatus(),
    };
  }

  // Dispose resources
  void dispose() {
    _audioStreamSubscription?.cancel();
    _audioRecorder.dispose();
  }
}